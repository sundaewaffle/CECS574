{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CECS574_TermPaperDemo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDfIj-Dn2ePL"
      },
      "source": [
        "Official sample program of Keras.\n",
        "\n",
        "This program train the basic model for MNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_beq1fotaAfo"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# image size\n",
        "row, col = 28, 28\n",
        "# learning configuration\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "# formating the image configuration with backend\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, row, col)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, row, col)\n",
        "    input_shape = (1, row, col)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], row, col, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], row, col, 1)\n",
        "    input_shape = (row, col, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WTYQElu2xds"
      },
      "source": [
        "Dependency\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlFEEoTKyWIk"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4APUA9x22gz"
      },
      "source": [
        "Load Dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb7ZN6zmyPnc",
        "outputId": "1e30472d-21b5-48f5-e189-72e8c8074d7a"
      },
      "source": [
        "# image size\n",
        "rows, cols = 224, 224\n",
        "\n",
        "# image generator\n",
        "training_set = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "testing_set = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# load dataset\n",
        "train_dir = 'drive/MyDrive/CECS574/Covid19-dataset/train'\n",
        "test_dir = 'drive/MyDrive/CECS574/Covid19-dataset/test'\n",
        "train_set = training_set.flow_from_directory(train_dir, target_size=(rows,cols), batch_size=8, class_mode='categorical')\n",
        "test_set = testing_set.flow_from_directory(test_dir, target_size=(rows,cols), batch_size=8, class_mode='categorical')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 251 images belonging to 3 classes.\n",
            "Found 66 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Fe48J8277y"
      },
      "source": [
        "Create Model, training, and evaluate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27lHDnbMuUW5",
        "outputId": "ddab21b9-8c2f-4f60-afde-5fcb16cede3e"
      },
      "source": [
        "# create model (AlexNet)\n",
        "model = Sequential([\n",
        "    # 1st layer - convolutional layer\n",
        "    Conv2D(48, (11,11), (4,4), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 2nd layer - convolutional layer\n",
        "    Conv2D(128, (5,5), (1,1), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 3rd layer - convolutional layer\n",
        "    Conv2D(192, (3,3), (1,1), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    # 4th layer - convolutional layer\n",
        "    Conv2D(192, (3,3), (1,1), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    # 2nd layer - convolutional layer\n",
        "    Conv2D(128, (3,3), (1,1), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # Flatten\n",
        "    Flatten(),\n",
        "    # Fully connected layers\n",
        "    Dense(2048, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(2048, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_set,\n",
        "    batch_size=8,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        "    validation_data=test_set\n",
        ")\n",
        "score = model.evaluate(test_set, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 129s 4s/step - loss: 1.9900 - accuracy: 0.5466 - val_loss: 2.3767 - val_accuracy: 0.3939\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 26s 800ms/step - loss: 0.6309 - accuracy: 0.8719 - val_loss: 3.8561 - val_accuracy: 0.3485\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 26s 804ms/step - loss: 0.3439 - accuracy: 0.9178 - val_loss: 0.6531 - val_accuracy: 0.7121\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 26s 794ms/step - loss: 0.2038 - accuracy: 0.9373 - val_loss: 0.9157 - val_accuracy: 0.6818\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 26s 799ms/step - loss: 0.1091 - accuracy: 0.9640 - val_loss: 0.4615 - val_accuracy: 0.8333\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 26s 793ms/step - loss: 0.1255 - accuracy: 0.9634 - val_loss: 0.4208 - val_accuracy: 0.8636\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 26s 793ms/step - loss: 0.1287 - accuracy: 0.9742 - val_loss: 0.4032 - val_accuracy: 0.8939\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 26s 792ms/step - loss: 0.1097 - accuracy: 0.9793 - val_loss: 0.9525 - val_accuracy: 0.8182\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 26s 791ms/step - loss: 0.1121 - accuracy: 0.9597 - val_loss: 0.6651 - val_accuracy: 0.8636\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 26s 796ms/step - loss: 0.0611 - accuracy: 0.9695 - val_loss: 0.5880 - val_accuracy: 0.8485\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 26s 801ms/step - loss: 0.0227 - accuracy: 0.9970 - val_loss: 0.6549 - val_accuracy: 0.8485\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 26s 795ms/step - loss: 0.0546 - accuracy: 0.9736 - val_loss: 0.6510 - val_accuracy: 0.8636\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 26s 790ms/step - loss: 0.0614 - accuracy: 0.9852 - val_loss: 0.5908 - val_accuracy: 0.8636\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 26s 799ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.9784 - val_accuracy: 0.8333\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 26s 809ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.6326 - val_accuracy: 0.8636\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 26s 807ms/step - loss: 0.0160 - accuracy: 0.9929 - val_loss: 0.7654 - val_accuracy: 0.8788\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 26s 794ms/step - loss: 0.0388 - accuracy: 0.9747 - val_loss: 0.4262 - val_accuracy: 0.8939\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 26s 795ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8939\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 26s 803ms/step - loss: 0.0851 - accuracy: 0.9654 - val_loss: 0.7337 - val_accuracy: 0.8788\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 26s 797ms/step - loss: 0.0161 - accuracy: 0.9929 - val_loss: 0.7606 - val_accuracy: 0.8636\n",
            "Test loss: 0.7606484293937683\n",
            "Test accuracy: 0.8636363744735718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gdZhYkfZbyY",
        "outputId": "8c56f939-bb0e-4117-e4e1-04456254bb5a"
      },
      "source": [
        "# load 1 image testing set\n",
        "testing_1_set = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "test_1_dir = 'drive/MyDrive/CECS574/Covid19-dataset/test_1'\n",
        "test_1_set = testing_set.flow_from_directory(test_1_dir, target_size=(rows,cols), batch_size=8, class_mode='categorical')\n",
        "\n",
        "prediction = model.predict(test_1_set)\n",
        "print('Probability of have COVID-19: ', prediction[0][0]*100, '%')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1 images belonging to 1 classes.\n",
            "Probability of have COVID-19:  99.99456405639648 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}