# -*- coding: utf-8 -*-
"""CECS574_TermPaperDemo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AHtlktmTH26pYDPYoaw3sk7MlynT3uEP

Official sample program of Keras.

This program train the basic model for MNIST.
"""

from __future__ import print_function

import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD

from keras import backend as K
from keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# image size
row, col = 28, 28
# learning configuration
batch_size = 128
num_classes = 10
epochs = 10
# formating the image configuration with backend
if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, row, col)
    x_test = x_test.reshape(x_test.shape[0], 1, row, col)
    input_shape = (1, row, col)
else:
    x_train = x_train.reshape(x_train.shape[0], row, col, 1)
    x_test = x_test.reshape(x_test.shape[0], row, col, 1)
    input_shape = (row, col, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')
# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

"""Dependency

"""

from __future__ import print_function
import os
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

"""Load Dataset.

"""

# image generator
training_set = ImageDataGenerator(
    rescale=1./255
)
testing_set = ImageDataGenerator(
    rescale=1./255
)

# load dataset
train_dir = 'drive/MyDrive/CECS574/Covid19-dataset/train'
test_dir = 'drive/MyDrive/CECS574/Covid19-dataset/test'
train_set = training_set.flow_from_directory(train_dir, target_size=(rows,cols), batch_size=8, class_mode='categorical')
test_set = testing_set.flow_from_directory(test_dir, target_size=(rows,cols), batch_size=8, class_mode='categorical')

"""Create Model, training, and evaluate.

"""

# image size
rows, cols = 224, 224

# create model (AlexNet)
model = Sequential([
    # 1st layer - convolutional layer
    Conv2D(48, (11,11), (4,4), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(3,3), strides=(2,2)),
    # 2nd layer - convolutional layer
    Conv2D(128, (5,5), (1,1), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(3,3), strides=(2,2)),
    # 3rd layer - convolutional layer
    Conv2D(192, (3,3), (1,1), activation='relu', padding='same'),
    BatchNormalization(),
    # 4th layer - convolutional layer
    Conv2D(192, (3,3), (1,1), activation='relu', padding='same'),
    BatchNormalization(),
    # 2nd layer - convolutional layer
    Conv2D(128, (3,3), (1,1), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(3,3), strides=(2,2)),
    # Flatten
    Flatten(),
    # Fully connected layers
    Dense(2048, activation='relu'),
    Dropout(0.25),
    Dense(2048, activation='relu'),
    Dropout(0.25),
    Dense(3, activation='softmax')
])

model.compile(
    optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True),
    loss="categorical_crossentropy",
    metrics=["accuracy"],
)

model.fit(
    train_set,
    batch_size=8,
    epochs=20,
    verbose=1,
    validation_data=test_set
)
score = model.evaluate(test_set, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])